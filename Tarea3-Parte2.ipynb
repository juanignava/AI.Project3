{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instituto Tecnológico de Costa Rica (ITCR)\n",
    "### Escuela de Computación\n",
    "### Curso: Inteligencia Artificial\n",
    " \n",
    "### Tercera tarea programada 2022-I\n",
    "\n",
    "### Parte 2 - ejercicio 2\n",
    "\n",
    "\n",
    "Estudiantes: Juan Ignacio Navarro Navarro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Descripción del problema y el objetivo del ejercicio\n",
    "\n",
    "Se desea utilizar una red neuronal recurrente LSTM utilzando pytorch para realizar un algortimo capaz de predecir la calificación dad por un comprrador. Estas calificaciones están relacionadas a el servicio de alquiler de apartamentos en una página web.\n",
    "\n",
    "Se utilizará como base para entrenar el modelo los datos de miles de revisiones anteriores y su respectiva calificación.\n",
    "\n",
    "El objetivo de este ejercicio es experimentar con el flujo completo de trabajo en un proyecto de aprendizaje automático para realizar análisis de sentimientos a partir de datos en lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Datos utilizados en el ejercicio\n",
    "\n",
    "Para este ejercicio se tomarán datos relacionados a las calificaciones de los usuarios usando el lenguaje natural para determinar el nivel de satisfacción con el servicio en el alquiler de apartamentos. \n",
    "\n",
    "Estos datos se encuentran en la siguiente dirección https://www.kaggle.com/code/wiktorbrk/trip-advisor-reviews-sentiment-analysis/notebook  de igual forma estos no son tan pesados como los del ejercicio anterior por lo que sí se incluyen en los datos en el zip de la entrega en el csv llamado tripadvisor_hotel_reviews.csv.\n",
    "\n",
    "Note que este archivo está compuesto de aproximadamente 20500 opiniones que dividen con la opinión textual y un número de  1 a 5 añadido por el mismo usuario. \n",
    "\n",
    "La idea de este ejercicio es a partir de algunas de las 20500 lograr formar un modelo capaz de predecir otra calificación solamente con el texto del lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Cargue y prepare los datos para ser introducidos a la red LSTM\n",
    "\n",
    "Primero se procede a importar las bilbiotecas necesarias para el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14b8305d650>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de funciones útiles para la carga de los datos. (aquí también se incluyen otras funciones de caracter general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones generales\n",
    "\n",
    "def max_values(x):\n",
    "    # Retorna el valor máximo y en índice o la posición del valor en un vector x.\n",
    "    # Parámetros: \n",
    "    #    x: vector con los datos. \n",
    "    # Salida: \n",
    "    #    out: valor \n",
    "    #    inds: índice\n",
    "    out, inds = torch.max(x,dim=1)   \n",
    "    return out, inds\n",
    "\n",
    "# Preparación de los datos \n",
    "def prepare_sequence(seq, to_ix):\n",
    "    # Retorna un tensor con los indices del diccionario para cada palabras en una oración.\n",
    "    # Parámetros:\n",
    "    #   seq: oración\n",
    "    #   to_ix: diccionario de palabras.\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "# Preparación de los datos \n",
    "def prepare_sequence_rating(seq, value, to_ix):\n",
    "    # Retorna un tensor con los indices del diccionario para cada palabras en una oración.\n",
    "    # Parámetros:\n",
    "    #   seq: oración\n",
    "    #   to_ix: diccionario de palabras.\n",
    "    idxs = [value for w in range(len(seq))]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'hotel', 'expensive', 'parking', 'got', 'good', 'deal', 'stay', 'hotel', 'anniversary,', 'arrived', 'late', 'evening', 'took', 'advice', 'previous', 'reviews', 'did', 'valet', 'parking,', 'check', 'quick', 'easy,', 'little', 'disappointed', 'non-existent', 'view', 'room', 'room', 'clean', 'nice', 'size,', 'bed', 'comfortable', 'woke', 'stiff', 'neck', 'high', 'pillows,', 'not', 'soundproof', 'like', 'heard', 'music', 'room', 'night', 'morning', 'loud', 'bangs', 'doors', 'opening', 'closing', 'hear', 'people', 'talking', 'hallway,', 'maybe', 'just', 'noisy', 'neighbors,', 'aveda', 'bath', 'products', 'nice,', 'did', 'not', 'goldfish', 'stay', 'nice', 'touch', 'taken', 'advantage', 'staying', 'longer,', 'location', 'great', 'walking', 'distance', 'shopping,', 'overall', 'nice', 'experience', 'having', 'pay', '40', 'parking', 'night,']\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  1,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27,  0, 28, 29, 30, 31, 32,\n",
      "        33, 34, 35, 36, 37, 38, 39, 40, 26, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 16, 36, 60,  7,  0, 61, 62, 63,\n",
      "        64, 65, 66, 67, 68, 69, 70, 71,  0, 72, 73, 74, 75,  3, 76])\n"
     ]
    }
   ],
   "source": [
    "# carga de los datos desde el csv con pandas\n",
    "df = pd.read_csv(r'tripadvisor_hotel_reviews.csv')\n",
    "# transformacion a minuscula\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# Diccionario de palabras con su calificación\n",
    "\"\"\"\n",
    "training_data = []\n",
    "test_data = []\n",
    "for i in df.index:\n",
    "    if (i < 50):\n",
    "        elem_tuple = df[\"review\"][i].split(), int(df[\"rating\"][i])\n",
    "        training_data.append(elem_tuple)\n",
    "    elif (i < 60):\n",
    "        elem_tuple = df[\"review\"][i].split(), int(df[\"rating\"][i])\n",
    "        test_data.append(elem_tuple)\n",
    "    else:\n",
    "        break\n",
    "\"\"\"\n",
    "training_data = []\n",
    "for i in df.index:\n",
    "    if (i > 20):\n",
    "        break\n",
    "    elem_tuple = df[\"review\"][i].split(), int(df[\"rating\"][i])\n",
    "    training_data.append(elem_tuple)\n",
    "\n",
    "test_data = []\n",
    "for i in df.index:\n",
    "    if (i > 20):\n",
    "        elem_tuple = df[\"review\"][i].split(), int(df[\"rating\"][i])\n",
    "        test_data.append(elem_tuple)\n",
    "    if (i > 30):\n",
    "        break\n",
    "\n",
    "# Diccionario las palabras\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "\n",
    "# Diccionariod e las etiquetas de cada posible calificación\n",
    "tag_to_ix = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n",
    "\n",
    "\n",
    "#Ejemplo de procesamiento de una oración\n",
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "print(training_data[0][0])                          \n",
    "print(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Calcule algunas estadísticas importantes\n",
    "\n",
    "Se la cantidad de registros por clase es la siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Estadísticas de los datos---\n",
      "Hay  3  para la categoría  0\n",
      "Hay  5  para la categoría  1\n",
      "Hay  5  para la categoría  2\n",
      "Hay  16  para la categoría  3\n",
      "Hay  12  para la categoría  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uutilizando el diccionario de entrenamiento se calcula la\n",
    "# de palabras con cierta calificación del 1 al 5\n",
    "\n",
    "lista_registros = [0] * 5\n",
    "lista_ext_comentarios = []\n",
    "\n",
    "for sent, tags in training_data:\n",
    "\n",
    "    # Actualización de lista de registros por clase\n",
    "    if (tags == 1):\n",
    "        lista_registros[0] += 1\n",
    "    if (tags == 2):\n",
    "        lista_registros[1] += 1\n",
    "    if (tags == 3):\n",
    "        lista_registros[2] += 1\n",
    "    if (tags == 4):\n",
    "        lista_registros[3] += 1\n",
    "    if (tags == 5):\n",
    "        lista_registros[4] += 1\n",
    "\n",
    "    # Actualizar lista del largo de comentarios\n",
    "    lista_ext_comentarios.append(len(sent))\n",
    "\n",
    "lista_ext_comentarios.sort()\n",
    "\n",
    "def imprimir_distribucion(lista_distro, lista_comentarios):\n",
    "    \"\"\"\n",
    "    Esta función se encarga de imprimir las estadísticas importantes\n",
    "    para el priblema como la cantidad de registros por clasei y distribución\n",
    "    del largo de comentarios.\n",
    "    \"\"\"\n",
    "    print(\"---Estadísticas de los datos---\")\n",
    "    for i in range(5):\n",
    "        print(\"Hay \", lista_registros[i], \" para la categoría \", i)\n",
    "\n",
    "    plot.hist(x=lista_comentarios, bins=20, color='#F2AB6D', rwidth=0.85)\n",
    "    plot.title('Histograma de largo de comentarios')\n",
    "    plot.xlabel('Largo de comentarios')\n",
    "    plot.ylabel('Frecuencia')\n",
    "\n",
    "    # Realizar un histograma para los comentarios\n",
    "\n",
    "imprimir_distribucion(lista_registros, lista_ext_comentarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Defina una red recurrente LSTM para procesar el conjutno de dato y clasificar los comentarios de usuario\n",
    "\n",
    "A continuación se muestra el modelo para procesar el conjutno de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo\n",
    "\n",
    "# El modelo es una clase que debe heredar de nn.Module\n",
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    # Incialización del modelo\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    " \n",
    "\n",
    "        # Primero se pasa la entrada a través de una capa Embedding. \n",
    "        # Esta capa construye una representación de los tokens de \n",
    "        # un texto donde las palabras que tienen el mismo significado \n",
    "        # tienen una representación similar.\n",
    "        \n",
    "        # Esta capa captura mejor el contexto y son espacialmente \n",
    "        # más eficientes que las representaciones vectoriales (one-hot vector).\n",
    "        # En Pytorch, se usa el módulo nn.Embedding para crear esta capa, \n",
    "        # que toma el tamaño del vocabulario y la longitud deseada del vector \n",
    "        # de palabras como entrada. \n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # El LSTM toma word_embeddings como entrada y genera los estados ocultos\n",
    "        # con dimensionalidad hidden_dim.  \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # La capa lineal mapea el espacio de estado oculto \n",
    "        # al espacio de clases\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # Pasada hacia adelante de la red. \n",
    "        # Parámetros:\n",
    "        #    sentence: la oración a procesar\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "\n",
    "        # Se utiliza softmax para devolver la probabilidad de cada etiqueta\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Definir los hiper-parámetros del proceso de entrenamiento\n",
    "\n",
    "A continuación se presenta una función de pérdida  NLLL (Negative Likelihood Loss) y el optimizador que usa el Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciación del modelo, definición de la función de pérdida y del optimizador   \n",
    "\n",
    "# Hiperparámetros de la red\n",
    "# Valores generalmente altos (32 o 64 dimensiones).\n",
    "# Se definen pequeños, para ver cómo cambian los pesos durante el entrenamiento.\n",
    "\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "# Instancia del modelo\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "\n",
    "# Función de pérdida: Negative Log Likelihood Loss (NLLL). \n",
    "# Generalmente utilizada en problemas de clasificacion con C clases.\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# Optimizador Stochastic Gradient Descent  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Separe las muestras en datos de entrenamiento y evaluación y entrene el modelo\n",
    "\n",
    "la separación de las muestras se realizó en la sección 3 donde los datos de entrenamiento se llaman `training_data` y los de prueba se llaman `test_data`\n",
    "\n",
    "El entrenamiento del modelo se realiza en esta función, aquí se relaciona cada palabra con la calificación dada en los datos de entrenamiento para poder entrenar el modelo definido anteriormente y que este ahora pueda utilizarse para reconocer las calificaciones nuevas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados luego del entrenamiento para la primera frase\n",
      "tensor([[-5.4042, -3.6914, -1.0554, -2.8354, -1.0575, -1.5302],\n",
      "        [-5.3253, -4.0851, -1.2200, -3.3607, -0.9495, -1.3415],\n",
      "        [-5.1797, -4.4465, -1.3192, -4.4475, -1.5685, -0.7027],\n",
      "        [-5.9934, -5.3166, -1.8383, -5.2850, -1.1034, -0.6998],\n",
      "        [-5.8026, -5.1869, -1.4697, -4.9359, -1.2847, -0.7392],\n",
      "        [-6.3158, -5.6214, -2.0837, -5.8004, -0.8920, -0.7825],\n",
      "        [-7.1640, -6.1011, -2.6003, -6.1802, -0.6964, -0.8621],\n",
      "        [-8.0071, -6.5219, -3.0782, -6.2776, -0.4652, -1.1323],\n",
      "        [-7.4995, -6.3265, -2.8227, -6.3490, -0.6952, -0.8267],\n",
      "        [-7.4313, -6.3557, -2.8856, -6.4818, -0.6670, -0.8508],\n",
      "        [-7.7297, -6.4945, -3.1086, -6.7012, -0.5651, -0.9575],\n",
      "        [-6.7134, -6.0529, -2.1430, -6.0239, -1.0122, -0.6669],\n",
      "        [-7.5308, -6.5431, -2.8328, -6.4963, -0.6322, -0.9008],\n",
      "        [-7.4076, -6.5994, -2.7152, -6.6968, -0.5655, -1.0147],\n",
      "        [-8.0966, -7.1639, -3.1751, -7.0840, -0.4435, -1.1568],\n",
      "        [-8.2576, -7.2575, -3.4198, -7.4071, -0.3368, -1.3797],\n",
      "        [-7.7709, -7.1938, -3.1380, -7.3128, -0.4946, -1.0643],\n",
      "        [-8.4682, -7.4510, -3.6229, -7.5353, -0.3027, -1.4560],\n",
      "        [-8.2957, -7.4500, -3.6944, -7.9324, -0.2790, -1.5259],\n",
      "        [-7.3527, -6.6633, -2.8434, -7.0092, -0.5192, -1.0673],\n",
      "        [-8.3432, -7.3132, -3.4736, -7.3924, -0.3495, -1.3379],\n",
      "        [-8.8506, -7.7294, -3.7177, -7.5771, -0.3253, -1.3770],\n",
      "        [-8.9047, -7.7617, -3.6231, -7.2577, -0.3310, -1.3711],\n",
      "        [-9.9201, -7.9492, -4.2792, -7.6776, -0.1605, -2.0132],\n",
      "        [-9.7264, -8.1329, -4.2200, -7.7982, -0.1777, -1.9152],\n",
      "        [-8.8715, -7.7569, -3.7712, -7.6513, -0.2702, -1.5478],\n",
      "        [-9.1454, -7.8952, -3.8796, -7.5956, -0.2798, -1.5033],\n",
      "        [-9.2457, -8.0030, -4.1352, -7.9786, -0.2531, -1.5757],\n",
      "        [-9.0407, -7.8749, -4.0532, -8.0080, -0.2601, -1.5569],\n",
      "        [-8.1830, -7.3956, -3.4436, -7.5677, -0.3760, -1.2728],\n",
      "        [-8.5555, -7.1812, -3.6073, -7.4829, -0.2644, -1.5911],\n",
      "        [-9.2873, -7.7027, -4.0666, -7.8338, -0.1766, -1.9392],\n",
      "        [-8.4868, -7.6520, -3.6759, -7.7461, -0.3501, -1.3134],\n",
      "        [-8.2006, -7.3558, -3.4907, -7.5682, -0.3464, -1.3437],\n",
      "        [-8.5179, -7.6130, -3.7912, -7.9166, -0.3069, -1.4244],\n",
      "        [-8.7647, -7.5498, -4.0247, -8.1544, -0.1799, -1.9253],\n",
      "        [-7.8980, -7.1272, -3.3669, -7.6002, -0.3918, -1.2449],\n",
      "        [-7.9029, -7.2622, -3.4038, -7.6359, -0.3795, -1.2695],\n",
      "        [-7.9049, -7.3106, -3.3687, -7.5230, -0.4422, -1.1352],\n",
      "        [-8.6151, -7.4454, -3.9568, -8.1365, -0.1898, -1.8795],\n",
      "        [-9.4358, -7.8623, -4.3782, -8.3049, -0.1443, -2.1112],\n",
      "        [-9.1440, -7.9049, -4.1176, -8.0447, -0.2369, -1.6408],\n",
      "        [-9.7067, -7.8469, -4.1778, -7.5335, -0.1942, -1.8313],\n",
      "        [-9.3958, -7.7540, -4.0002, -7.3988, -0.2583, -1.5691],\n",
      "        [-8.9371, -7.5390, -3.8881, -7.5473, -0.3207, -1.3757],\n",
      "        [-8.1977, -6.0373, -3.1313, -5.8193, -0.6694, -0.8239],\n",
      "        [-8.9656, -7.4341, -3.7543, -7.2578, -0.3202, -1.3896],\n",
      "        [-9.3415, -7.6557, -4.1336, -7.6604, -0.2082, -1.7668],\n",
      "        [-8.0029, -7.2120, -3.2567, -7.2777, -0.4794, -1.0771],\n",
      "        [-8.7924, -7.1813, -3.5824, -7.1042, -0.3013, -1.4671],\n",
      "        [-9.0781, -7.5732, -3.9848, -7.6994, -0.2334, -1.6688],\n",
      "        [-8.7223, -7.4614, -3.7893, -7.6344, -0.2940, -1.4658],\n",
      "        [-9.5745, -7.8604, -4.2445, -7.8783, -0.1849, -1.8733],\n",
      "        [-8.4441, -7.5814, -3.5815, -7.5730, -0.3543, -1.3119],\n",
      "        [-8.6988, -7.6075, -3.7710, -7.6762, -0.3101, -1.4168],\n",
      "        [-8.1263, -7.3368, -3.4372, -7.5776, -0.3798, -1.2645],\n",
      "        [-8.0325, -6.9937, -3.2833, -7.3039, -0.3451, -1.3766],\n",
      "        [-8.5072, -7.2898, -3.6007, -7.4965, -0.2835, -1.5227],\n",
      "        [-8.8950, -7.6526, -3.7519, -7.4550, -0.3216, -1.3848],\n",
      "        [-8.2440, -7.3783, -3.4222, -7.4612, -0.3944, -1.2317],\n",
      "        [-8.2918, -7.3215, -3.4701, -7.4312, -0.3691, -1.2873],\n",
      "        [-8.6263, -7.5361, -3.5693, -7.3246, -0.3640, -1.2890],\n",
      "        [-8.7868, -7.5092, -3.5973, -7.2028, -0.3426, -1.3424],\n",
      "        [-8.9803, -7.5052, -3.6967, -7.1963, -0.3192, -1.3982],\n",
      "        [-9.0564, -7.6968, -3.7942, -7.3020, -0.3041, -1.4335],\n",
      "        [-8.8990, -7.3322, -3.7564, -7.3329, -0.2568, -1.6012],\n",
      "        [-9.5867, -7.9403, -4.3122, -8.0238, -0.2000, -1.7892],\n",
      "        [-9.0643, -7.8084, -3.7739, -7.3371, -0.2811, -1.5100],\n",
      "        [-8.9860, -7.4909, -3.7533, -7.4686, -0.2426, -1.6568],\n",
      "        [-9.0561, -7.7065, -4.0023, -7.8913, -0.2360, -1.6553],\n",
      "        [-8.2766, -7.4387, -3.5687, -7.6573, -0.3187, -1.4131],\n",
      "        [-8.8417, -7.7124, -3.9656, -7.9954, -0.2500, -1.6030],\n",
      "        [-8.9038, -7.6206, -3.8340, -7.6336, -0.2336, -1.6842],\n",
      "        [-9.2695, -7.9375, -4.1842, -8.0397, -0.2320, -1.6554],\n",
      "        [-8.9907, -7.4434, -3.7716, -7.4668, -0.2346, -1.6884],\n",
      "        [-8.5213, -7.5236, -3.6500, -7.6708, -0.3254, -1.3839],\n",
      "        [-8.5841, -7.5713, -3.8080, -7.9000, -0.2706, -1.5426],\n",
      "        [-8.4585, -7.4581, -3.6718, -7.7292, -0.3192, -1.3999],\n",
      "        [-9.2636, -7.4311, -3.9696, -7.5002, -0.2181, -1.7382],\n",
      "        [-8.4302, -7.6121, -3.5747, -7.6007, -0.3938, -1.2165],\n",
      "        [-8.6140, -7.2393, -3.6180, -7.4748, -0.2629, -1.5953],\n",
      "        [-9.5462, -7.9381, -4.3039, -8.0343, -0.1800, -1.8939],\n",
      "        [-8.9644, -7.7058, -3.9009, -7.7245, -0.2640, -1.5570],\n",
      "        [-9.1051, -7.4177, -3.6865, -6.9356, -0.2968, -1.4694],\n",
      "        [-8.5886, -7.2714, -3.5699, -7.1623, -0.3873, -1.2333],\n",
      "        [-8.9174, -7.5906, -3.8501, -7.5481, -0.3015, -1.4362],\n",
      "        [-9.4297, -7.9498, -4.2695, -8.0982, -0.2136, -1.7281]])\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo \n",
    "\n",
    "# Valores antes de entrenar\n",
    "# El elemento i, j de la salida es la puntuación entre la etiqueta j para la palabra i.\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    \n",
    "    # Clasificación    \n",
    "    #print(tag_scores)\n",
    "\n",
    "# Épocas de entrenamiento\n",
    "for epoch in range(50):  \n",
    "    for sentence, tags in training_data:\n",
    "        ## Paso 1. Pytorch acumula los gradientes.\n",
    "        # Es necesario limpiarlos\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Paso 2. Se preparan las entradas, es decir, se convierten a\n",
    "        # tensores de índices de palabras.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence_rating(sentence, tags, tag_to_ix)\n",
    "\n",
    "        # Paso 3. Se genera la predicción (forward pass).\n",
    "        #print(sentence_in)\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Paso 4. se calcula la pérdida, los gradientes, y se actualizan los \n",
    "        # parámetros por medio del optimizador.\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Despligue de la puntuación luego del entrenamiento\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "   \n",
    "    print(\"Resultados luego del entrenamiento para la primera frase\")\n",
    "    # Las palabras en una oración se pueden etiquetar de tres formas.\n",
    "    # La primera oración tiene 4 palabras \"El perro come manzana\"\n",
    "    # por eso el tensor de salida tiene 4 elementos. \n",
    "    # Cada elemento es un vector de pesos que indica cuál etiqueta tiene más\n",
    "    # posibilidad de estar asociada a la palabra. Es decir hay que calcular \n",
    "    # la posición del valor máximo\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases\n",
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\juan navarro\\Documents\\Implementaciones - AI\\AI.Project3\\Tarea3-Parte2.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan%20navarro/Documents/Implementaciones%20-%20AI/AI.Project3/Tarea3-Parte2.ipynb#ch0000007?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(tag_to_ix)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan%20navarro/Documents/Implementaciones%20-%20AI/AI.Project3/Tarea3-Parte2.ipynb#ch0000007?line=22'>23</a>\u001b[0m \u001b[39m#Frase 1\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan%20navarro/Documents/Implementaciones%20-%20AI/AI.Project3/Tarea3-Parte2.ipynb#ch0000007?line=23'>24</a>\u001b[0m \u001b[39m# Las palabras en una oración se pueden etiquetar de tres formas.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan%20navarro/Documents/Implementaciones%20-%20AI/AI.Project3/Tarea3-Parte2.ipynb#ch0000007?line=24'>25</a>\u001b[0m \u001b[39m# La primera oración tiene 3 palabras \"El perro juega\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan%20navarro/Documents/Implementaciones%20-%20AI/AI.Project3/Tarea3-Parte2.ipynb#ch0000007?line=28'>29</a>\u001b[0m \u001b[39m#   Ejemplo 1: \"El perro juega\" [\"DET\", \"NN\", \"V\"]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan%20navarro/Documents/Implementaciones%20-%20AI/AI.Project3/Tarea3-Parte2.ipynb#ch0000007?line=29'>30</a>\u001b[0m \u001b[39m# Ejemplo: salida 0, 1, 2 con {\"DET\": 0, \"NN\": 1, \"V\": 2} => DET, NN, V \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/juan%20navarro/Documents/Implementaciones%20-%20AI/AI.Project3/Tarea3-Parte2.ipynb#ch0000007?line=30'>31</a>\u001b[0m test_examples(test_data[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "# ¿Cómo se probaría el modelo?\n",
    "\n",
    "def test_examples(test_data):\n",
    "\n",
    "   with torch.no_grad():\n",
    "      inputs = prepare_sequence(test_data, word_to_ix)\n",
    "      tag_scores = model(inputs)\n",
    "    \n",
    " \n",
    "   print(\"FRASE\") \n",
    "   print(\"La frase original\", test_data)    \n",
    "   print(\"La frase original preprocesada\", inputs)\n",
    "   print(\"Salida del modelo\", tag_scores)\n",
    "   print(\"Valores máximos e índices\", max_values(tag_scores))    \n",
    "    \n",
    "\n",
    "#print(\"Índice de palabras\")\n",
    "#print(\"word_to_idx\", word_to_ix)\n",
    "\n",
    "print(\"Clases\")\n",
    "print(tag_to_ix)\n",
    "\n",
    "#Frase 1\n",
    "# Las palabras en una oración se pueden etiquetar de tres formas.\n",
    "# La primera oración tiene 3 palabras \"El perro juega\"\n",
    "# por eso el tensor de salida tiene 3 elementos. \n",
    "# Cada elemento es un vector de probabilidad de estar asociada a una clase. \n",
    "# Es decir hay que calcular la posición del valor máximo. \n",
    "#   Ejemplo 1: \"El perro juega\" [\"DET\", \"NN\", \"V\"]\n",
    "# Ejemplo: salida 0, 1, 2 con {\"DET\": 0, \"NN\": 1, \"V\": 2} => DET, NN, V \n",
    "test_examples(test_data[0][0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e868495d694aed0b609784ddbe0f4170fa3a0dc0623318ab45c72f62595d740c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
