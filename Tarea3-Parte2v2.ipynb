{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instituto Tecnológico de Costa Rica (ITCR)\n",
    "### Escuela de Computación\n",
    "### Curso: Inteligencia Artificial\n",
    " \n",
    "### Tercera tarea programada 2022-I\n",
    "\n",
    "### Parte 2 - ejercicio 2\n",
    "\n",
    "\n",
    "Estudiantes: Juan Ignacio Navarro Navarro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Descripción del problema y el objetivo del ejercicio\n",
    "\n",
    "Se desea utilizar una red neuronal recurrente LSTM utilzando pytorch para realizar un algortimo capaz de predecir la calificación dada por un comprrador. Estas calificaciones están relacionadas a el servicio de alquiler de apartamentos en una página web.\n",
    "\n",
    "Se utilizará como base para entrenar el modelo los datos de miles de revisiones anteriores y su respectiva calificación.\n",
    "\n",
    "El objetivo de este ejercicio es experimentar con el flujo completo de trabajo en un proyecto de aprendizaje automático para realizar análisis de sentimientos a partir de datos en lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Datos utilizados en el ejercicio\n",
    "\n",
    "Para este ejercicio se tomarán datos relacionados a las calificaciones de los usuarios usando el lenguaje natural para determinar el nivel de satisfacción con el servicio en el alquiler de apartamentos. \n",
    "\n",
    "Estos datos se encuentran en la siguiente dirección https://www.kaggle.com/code/wiktorbrk/trip-advisor-reviews-sentiment-analysis/notebook  de igual forma estos no son tan pesados como los del ejercicio anterior por lo que sí se incluyen en los datos en el zip de la entrega en el csv llamado tripadvisor_hotel_reviews.csv.\n",
    "\n",
    "Note que este archivo está compuesto de aproximadamente 20500 opiniones que dividen en lo siguiente:\n",
    "\n",
    "- review: la opinión textual de un cliente utilizando el lenguaje natural\n",
    "- rating: es un número de  1 a 5 añadido por el mismo usuario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Cargue y prepare los datos para ser introducidos a la red LSTM\n",
    "\n",
    "Primero se procede a importar las bilbiotecas necesarias para el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas requeridas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de los datos utilizando pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20491, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive parking got good deal sta...       4\n",
       "1  ok nothing special charge diamond member hilto...       2\n",
       "2  nice rooms not 4* experience hotel monaco seat...       3\n",
       "3  unique, great stay, wonderful time hotel monac...       5\n",
       "4  great stay great stay, went seahawk game aweso...       5"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer los datos de ejemplos\n",
    "reviews = pd.read_csv(\"tripadvisor_hotel_reviews.csv\")\n",
    "print(reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>love monaco staff husband stayed hotel crazy w...</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cozy stay rainy city, husband spent 7 nights m...</td>\n",
       "      <td>5</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>excellent staff, housekeeping quality hotel ch...</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hotel stayed hotel monaco cruise, rooms genero...</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>excellent stayed hotel monaco past w/e delight...</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>poor value stayed monaco seattle july, nice ho...</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nice value seattle stayed 4 nights late 2007. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nice hotel good location hotel kimpton design ...</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nice hotel not nice staff hotel lovely staff q...</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>great hotel night quick business trip, loved l...</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>horrible customer service hotel stay february ...</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>disappointed say anticipating stay hotel monac...</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fantastic stay monaco seattle hotel monaco hol...</td>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>good choice hotel recommended sister, great lo...</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hmmmmm say really high hopes hotel monaco chos...</td>\n",
       "      <td>3</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  rating  review_length\n",
       "0   nice hotel expensive parking got good deal sta...       4             87\n",
       "1   ok nothing special charge diamond member hilto...       2            250\n",
       "2   nice rooms not 4* experience hotel monaco seat...       3            217\n",
       "3   unique, great stay, wonderful time hotel monac...       5             89\n",
       "4   great stay great stay, went seahawk game aweso...       5            191\n",
       "5   love monaco staff husband stayed hotel crazy w...       5            134\n",
       "6   cozy stay rainy city, husband spent 7 nights m...       5            101\n",
       "7   excellent staff, housekeeping quality hotel ch...       4             85\n",
       "8   hotel stayed hotel monaco cruise, rooms genero...       5             59\n",
       "9   excellent stayed hotel monaco past w/e delight...       5             35\n",
       "10  poor value stayed monaco seattle july, nice ho...       2             47\n",
       "11  nice value seattle stayed 4 nights late 2007. ...       4             52\n",
       "12  nice hotel good location hotel kimpton design ...       4             84\n",
       "13  nice hotel not nice staff hotel lovely staff q...       3             70\n",
       "14  great hotel night quick business trip, loved l...       4             27\n",
       "15  horrible customer service hotel stay february ...       1            214\n",
       "16  disappointed say anticipating stay hotel monac...       2            242\n",
       "17  fantastic stay monaco seattle hotel monaco hol...       5            144\n",
       "18  good choice hotel recommended sister, great lo...       5             22\n",
       "19  hmmmmm say really high hopes hotel monaco chos...       3            156"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar las columnas relevantes y calcular la longitud de las oraciones\n",
    "reviews = reviews[['Review', 'Rating']]\n",
    "reviews.columns = ['review', 'rating']\n",
    "reviews['review_length'] = reviews['review'].apply(lambda x: len(x.split()))\n",
    "reviews.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio de la numeración de la clasificaciones de 0 a 4\n",
    "zero_numbering = {1:0, 2:1, 3:2, 4:3, 5:4}\n",
    "reviews['rating'] = reviews['rating'].apply(lambda x: zero_numbering[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de las principales estadísitcas de los datos, note que se muestran la cantidad de datos definidos y diferentes medidas de tendencia central de los mismos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20491.00</td>\n",
       "      <td>20491.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.95</td>\n",
       "      <td>104.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.23</td>\n",
       "      <td>100.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.00</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.00</td>\n",
       "      <td>124.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.00</td>\n",
       "      <td>1931.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating  review_length\n",
       "count 20491.00       20491.00\n",
       "mean      2.95         104.38\n",
       "std       1.23         100.66\n",
       "min       0.00           7.00\n",
       "25%       2.00          48.00\n",
       "50%       3.00          77.00\n",
       "75%       4.00         124.00\n",
       "max       4.00        1931.00"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estadísticas\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenización y preparación de los datos para ser introducidos a la red LSTM, estos tokens son necesarios para poder distinguir entre las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 49116\n",
      "num_words after: 25185\n"
     ]
    }
   ],
   "source": [
    "# Tokenización: proceso de separar un fragmento de texto en \n",
    "#  unidades más pequeñas llamadas tokens. \n",
    "#  Los tokens pueden ser palabras, caracteres o sub-palabras.\n",
    "tok = spacy.blank(\"en\")\n",
    "\n",
    "def tokenize (text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n",
    "    nopunct = regex.sub(\" \", text.lower())\n",
    "    return [token.text for token in tok.tokenizer(nopunct)]\n",
    "\n",
    "# Se cuenta la cantidad de ocurrencias de cada token \n",
    "# en el corpus.\n",
    "\n",
    "#count number of occurences of each word\n",
    "counts = Counter()\n",
    "for index, row in reviews.iterrows():\n",
    "    counts.update(tokenize(row['review']))\n",
    "\n",
    "# Se eliminan los tokens que no ocurren con mucha frecuencia (menos de dos veces). \n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el vocabulario\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodificación de las oraciones, note que se toma un máximo de 70 palabras como máximo por cada texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  rating  review_length  \\\n",
      "0  nice hotel expensive parking got good deal sta...       3             87   \n",
      "1  ok nothing special charge diamond member hilto...       1            250   \n",
      "2  nice rooms not 4* experience hotel monaco seat...       2            217   \n",
      "3  unique, great stay, wonderful time hotel monac...       4             89   \n",
      "4  great stay great stay, went seahawk game aweso...       4            191   \n",
      "\n",
      "                                             encoded  \n",
      "0  [[2, 3, 4, 5, 6, 7, 8, 9, 3, 10, 11, 12, 13, 1...  \n",
      "1  [[79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 78, ...  \n",
      "2  [[2, 234, 39, 77, 74, 3, 235, 90, 7, 3, 236, 2...  \n",
      "3  [[347, 11, 69, 9, 11, 348, 349, 3, 235, 11, 68...  \n",
      "4  [[69, 9, 69, 9, 11, 393, 394, 395, 396, 11, 39...  \n"
     ]
    }
   ],
   "source": [
    "def encode_sentence(text, vocab2index, N=70):\n",
    "    \"\"\"\n",
    "    Codificación de una oración antes de ser utilizada por el modelo. \n",
    "    Parámetros:\n",
    "       text: el texto a procesar\n",
    "       vocab2index: diccionario con el vocabulario a utilizar. \n",
    "       N: largo máximo\n",
    "    \"\"\"\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    \n",
    "    # El get en diccionario permite definir un valor si un item no existe (\"UNK\").  \n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    \n",
    "    # Largo máximo del resultado.\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length\n",
    "\n",
    "reviews['encoded'] = reviews['review'].apply(lambda x: np.array(encode_sentence(x,vocab2index ), dtype=object))\n",
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Calcule algunas estadísticas importantes\n",
    "\n",
    "Las estadísticas de los datos se mostraron en la sección anterior antes de que se hicieran los tokens. Identificación del balanceo de las clases a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 6039, 1: 1793, 2: 2184, 4: 9054, 0: 1421})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificación de qué tan bien balanceadas están las clases.\n",
    "Counter(reviews['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Separación de las muestras en datos de entrenamiento y evaluación\n",
    "\n",
    "a continuación se realiza la respectiva separación y crea un Dataset para el manejo de los datos en el modelo y la evaluación del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción de características y taget.\n",
    "X = list(reviews['encoded'])\n",
    "y = list(reviews['rating'])\n",
    "\n",
    "# División de datos de entrenamiento y validación\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definción de la clase Dataset para manejo de los datos\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de los datasets de entrenamiento y validación\n",
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Defina una red recurrente LSTM. y 6) Definición de los hiperparámetros\n",
    "\n",
    "A continuación se muestra el modelo de la red con su respectiva función de forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_fixed_len(torch.nn.Module) :\n",
    "    \"\"\"\n",
    "    Clase para realizar la clasificación de las oraciones. \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, tagset_size=5) :\n",
    "        \"\"\"\n",
    "        Inicialización de la clase.\n",
    "        Parámetros:\n",
    "           embedding_dim: dimesionalidad del vector de palabras. \n",
    "           hidden_dim: dimensión de la capa oculta de la red. \n",
    "           vocab_size: tamaño del vocabulario.  \n",
    "           tagset_size: número de clases.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "        # Durante el entrenamiento, pone a cero aleatoriamente algunos de los elementos \n",
    "        # del tensor de entrada con probabilidad p utilizando muestras de una \n",
    "        # distribución de Bernoulli. Esta ha demostrado ser una técnica eficaz para la regularización.\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train_loss = []\n",
    "gen_val_loss = []\n",
    "gen_val_acc = []\n",
    "gen_val_rmse = []\n",
    "\n",
    "def train_model(model, epochs=10, lr=0.001):\n",
    "    \"\"\"\n",
    "    Entrenamiento del modelo utilizando PyTorch.\n",
    "    \"\"\"\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.long()\n",
    "            y_pred = model(x, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "\n",
    "        gen_train_loss.append(sum_loss/total)\n",
    "        val_loss, val_acc, val_rmse, y, pred = validation_metrics(model, val_dl)\n",
    "        gen_val_loss.append(val_loss)\n",
    "        gen_val_acc.append(val_acc)\n",
    "        gen_val_rmse.append(val_rmse)\n",
    "\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "\n",
    "TP = []\n",
    "FP = []\n",
    "FN = []\n",
    "TN = []\n",
    "\n",
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    \n",
    "    i = 0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        print(y)\n",
    "        print(pred)\n",
    "\n",
    "        # Calculo de datos para la matriz de confusión\n",
    "        if (pred[i] == 4):\n",
    "            if (y[i] == 4):\n",
    "                TP.append(1)\n",
    "            else:\n",
    "                FP.append(1)\n",
    "        else:\n",
    "            if(y[i] == 4):\n",
    "                FN.append(1)\n",
    "            else:\n",
    "                FN.append(1)\n",
    "        i +=1\n",
    "\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total, y, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "train loss 1.385, val loss 1.359, val accuracy 0.441, and val rmse 1.608\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "train loss 1.289, val loss 1.344, val accuracy 0.427, and val rmse 1.533\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 1, 4,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 3, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "train loss 1.079, val loss 1.194, val accuracy 0.468, and val rmse 1.223\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 4, 4])\n",
      "train loss 0.925, val loss 1.180, val accuracy 0.502, and val rmse 1.050\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 3, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 2,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 4, 4])\n",
      "train loss 0.898, val loss 1.287, val accuracy 0.489, and val rmse 1.101\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 3, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 4, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 3, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 3, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 3, 4])\n",
      "train loss 0.739, val loss 1.192, val accuracy 0.536, and val rmse 0.951\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 3, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 3, 4])\n",
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 5000\n",
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "\n",
    "model_fixed =  LSTM_fixed_len(vocab_size, 50, 50)\n",
    "train_model(model_fixed, epochs=30, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Evaluación del modelo resultante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 4,  ..., 4, 3, 4])\n",
      "tensor([4, 4, 3,  ..., 4, 3, 4])\n",
      "Exactitud tensor(0.5396)\n",
      "Raíz del error cuadrático medio 0.9398862653289952\n"
     ]
    }
   ],
   "source": [
    "# Validación del modelo \n",
    "average_loss, accuracy, average_rmse, y, pred = validation_metrics (model_fixed, val_dl)\n",
    "\n",
    "print (\"Exactitud\", accuracy)\n",
    "print(\"Raíz del error cuadrático medio\", average_rmse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Grafique la curva de error con datos de entrenamiento y prueba de todas las épocas\n",
    "\n",
    "La curva de error se muestra a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = []\n",
    "\n",
    "for i in range(28):\n",
    "    x.append(i+1)\n",
    "\n",
    "\n",
    "# Graficar ambas funciones\n",
    "pyplot.plot(x, gen_val_acc[2:], label = \"Train\")\n",
    "pyplot.plot(x, gen_train_loss[2:], label = \"Validation\")\n",
    "\n",
    "\n",
    "pyplot.legend()\n",
    "\n",
    "\n",
    "# Establecer el color de los ejes.\n",
    "pyplot.axhline(0, color=\"black\")\n",
    "pyplot.axvline(0, color=\"black\")\n",
    "\n",
    "pyplot.title(\"Model train vs validation loss\")\n",
    "\n",
    "# Limitar los valores de los ejes.\n",
    "#pyplot.xlim(-10, 10)\n",
    "pyplot.ylim(0.3, 1.4)\n",
    "pyplot.xlabel(\"Cantidad de etapas\")\n",
    "pyplot.ylabel(\"Loss\")\n",
    "# Guardar gráfico como imágen PNG.\n",
    "# Mostrarlo.\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Evalúe el model resultante utilizando una matriz de confusión y métricas extraidas a partir de esta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión de muestra en el siguiente bloque. En los comentarios se explica el resultado obtenido. Además las métricas de exactitud, presición, exhaustividad y F1 se muestran después en los resultados. Note que el cálculo respectivo corresponde a cada una de las clases ya que existen más de dos clases (el modelo de clasificación no es binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATRIZ DE CONFUSION\n",
      "\t1\t2\t3\t4\t5\n",
      "1 \t 106\t77\t61\t30\t10\t\n",
      "2 \t 57\t76\t96\t85\t33\t\n",
      "3 \t 21\t50\t113\t186\t95\t\n",
      "4 \t 7\t25\t85\t412\t669\t\n",
      "5 \t 2\t5\t31\t262\t1505\t\n",
      "\n",
      "EXACTITUD: la proporción de prediccones que el modelo clasificó correctamente en el total de clases del modelo\n",
      "0.5396438155647719\n",
      "\n",
      "PRECISIÓN: Proporción de instancias correctas entre las recuperadas solamente considerando las positivas\n",
      "precisión en la clase  1  es  0.5492227979274611\n",
      "precisión en la clase  2  es  0.3261802575107296\n",
      "precisión en la clase  3  es  0.2927461139896373\n",
      "precisión en la clase  4  es  0.42256410256410254\n",
      "precisión en la clase  5  es  0.6509515570934256\n",
      "\n",
      "EXHAUSTIVIDAD: proporción de positivos que se identificó correctamente\n",
      "exhaustividad en la clase  1  es  0.3732394366197183\n",
      "exhaustividad en la clase  2  es  0.21902017291066284\n",
      "exhaustividad en la clase  3  es  0.24301075268817204\n",
      "exhaustividad en la clase  4  es  0.34390651085141904\n",
      "exhaustividad en la clase  5  es  0.8337950138504155\n",
      "\n",
      "F1: equilibrio entre la precisión y el recall\n",
      "f1 en la clase  1  es  0.4444444444444444\n",
      "f1 en la clase  2  es  0.2620689655172414\n",
      "f1 en la clase  3  es  0.26556991774383076\n",
      "f1 en la clase  4  es  0.37919926369075013\n",
      "f1 en la clase  5  es  0.731114889482633\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión:\n",
    "# Como entrada se toman las listas que contienen los valores predecidos por el\n",
    "# modelo en la variable 'pred' y en la variable 'y' los valores esperados por\n",
    "# el modelo\n",
    "\n",
    "# la bilbioteca skilearn contiene los siguientes métodos para realizar los cáculos\n",
    "# métricas extraidas del modelo\n",
    "\n",
    "# Como esta matriz corresponde a una formada por varias clases el valor que se representa\n",
    "# en cada elemento son los casos que funcionaron, por ejemplo en la posición 3, 3 se muestran\n",
    "# la cantidad de valores 3 que tuvieron un valor predecido igual a 3\n",
    "\n",
    "print(\"MATRIZ DE CONFUSION\")\n",
    "confusion = confusion_matrix(y, pred)\n",
    "print(\"\\t1\\t2\\t3\\t4\\t5\")\n",
    "for i in range(5):\n",
    "    texto = \"\"\n",
    "    for j in range(5):\n",
    "        texto += str(confusion[i][j]) + \"\\t\"\n",
    "\n",
    "    print(i+1, \"\\t\", texto)\n",
    "\n",
    "# Exactitud: la proporciónd e prediccones que el modelo clasificó correctamente\n",
    "\n",
    "print(\"\\nEXACTITUD: la proporción de prediccones que el modelo clasificó correctamente en el total de clases del modelo\")\n",
    "print(accuracy_score(y, pred))\n",
    "\n",
    "# Precisión: porcentaje de los identificadores positivos que fueron recuperados\n",
    "print(\"\\nPRECISIÓN: Proporción de instancias correctas entre las recuperadas solamente considerando las positivas\")\n",
    "\n",
    "presicion = precision_score(y, pred, average=None, zero_division=True)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"precisión en la clase \", i+1, \" es \", presicion[i])\n",
    "\n",
    "\n",
    "# Exhausitividad: proporción de positivos que se identificó correctamente\n",
    "print(\"\\nEXHAUSTIVIDAD: proporción de positivos que se identificó correctamente\")\n",
    "\n",
    "exhaustividad = recall_score(y, pred, average= None)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"exhaustividad en la clase \", i+1, \" es \", exhaustividad[i])\n",
    "\n",
    "\n",
    "# F1: equilibrio entra la precisión y el recall\n",
    "print(\"\\nF1: equilibrio entre la precisión y el recall\")\n",
    "\n",
    "f1= f1_score(y, pred, average=None)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"f1 en la clase \", i+1, \" es \", f1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Analice los resultados\n",
    "\n",
    "Note que basado en los resultados el se tienen los siguiente puntos bajos:\n",
    "- Exactitud del tensor de 0.5396. Es una exactitud baja y se puede apreciar que en cada clase se cuenta con una precisión y exhaustividad baja debido al mismo problema.\n",
    "- La curva de error entre los datos de entrenamiento y las pruebas por cada una de las épocas no converge (no parece como que las líneas de la gráfica se tocan)\n",
    "\n",
    "Estos detalles pueden ser corregidos con más épocas de entrenamiento, por lo general se observan más de 30 épocas que son las que se definieron en este ejercicio pero se tiene el problema de que la simulación para más épocas dura bastante en mi computadora y la aplicación se cae. En una computadora más potente estos puntos bajos se pueden atender con más épocas. \n",
    "\n",
    "Otra solución para este problema que en este caso no se corrigió para poder ver el comportamiento completo es juntar clases, ya que se puede observar en la sección 4 que las clases no están tan bien balanceadas, esto porque se cuenta con muchos comentarios de 5 estrellas en comparación con el resto de las categorías.\n",
    "\n",
    "También se cuenta con un punto favorable que es la medición que se hizo del error cuadrático medio en el modelo, este es de 0.9398 lo cuál es bajo y nos permite saber que el modelo es bueno y que solo ocupa desarrollarse por más tiempo. Otro detalle que se puede destacar es que la evaluación de los nuevos comentarios se realiza rápidamente, en la sección 9 del documento se puede ver que la evaluación con los comentarios de prueba se realizó en menos de 2 segundos, lo cuál nos permite ver la utilidad de este modelo porque de hacerse manual el hecho de solamente leer 1 de los comentarios toma más que lo que dura la inteligencia artificial con miles de estos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11) Conclusiones\n",
    "\n",
    "- Una red de memoria de corto y largo plazo permite se adapta perfectamente a la clasificación del lenguaje natural. Como las palabras por si solas pueden tener diferentes significados se tienen que analizar con respecto a lo escrito anteriormente y debe influir en las siguientes palabras.\n",
    "\n",
    "- Al aumentar la cantidad de capas por las que pasa el análisis se mejora la curva de error (al disminuir el mismo), esto por que como se mencionó en la conclusión anterior un análisis en los resultados de las plabaras anteriores puede cambiar el contexto de la oración.\n",
    "\n",
    "- Un modelo de reconocimiento del lenguaje natural que se encuentre en constante entrenamiento es capaz de realizar predicciones de miles de opiniones en pocos segundos, este análisis acelerado le permite a las empresas mejorar sus servicios y acelerar sus procesos por lo que tiene muchas utilidades en el mercado moderno.\n",
    "\n",
    "- Una exactitud baja nos dice que el modelo no está teniendo buenos resultados, pero el error cuadrático medio que es la desviación entre los errores no indica que todos los resultados están desviados hacia el mismo lugar, es decir que con la corrección general del modelo el resto de los resultados se van acomodar correctamente y así generar el modelo deseado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "Mora, María (2022) \"Redes Neuronales Recurrentes\". Instituto Tecnológico de Costa Rica. I Semestre 2022.\n",
    "\n",
    "Shin, T. (2020) \"Comprensión de la Matriz de Confusión y Cómo Implementarla en Python\". Disponible en: https://www.datasource.ai/es/data-science-articles/comprension-de-la-matriz-de-confusion-y-como-implementarla-en-python\n",
    "\n",
    "Kaggle (2020) \"Trip advisor reviews sentiment analysis\". Disponible en: https://www.kaggle.com/code/wiktorbrk/trip-advisor-reviews-sentiment-analysis/notebook\n",
    "\n",
    "Silipo, R. (2019) \"Confusion Matrix and Class Stadistics\". Disponible en: https://towardsdatascience.com/confusion-matrix-and-class-statistics-68b79f4f510b"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e868495d694aed0b609784ddbe0f4170fa3a0dc0623318ab45c72f62595d740c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
